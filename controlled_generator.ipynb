{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "test_split = 0.0\n",
    "intermediate_dim = 100\n",
    "z_dim = 10\n",
    "c_dim = 1\n",
    "seq_length = 5\n",
    "epsilon_std = 1.\n",
    "optimizer = 'rmsprop'\n",
    "\n",
    "file = 'robinson_crusoe.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_one_hot(index, count):\n",
    "    one_hot = [0] * count\n",
    "    one_hot[index] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextController:\n",
    "    def __init__(self, text, seq_length):\n",
    "        self.seq_length = seq_length\n",
    "        self.text = self.format_text(text)\n",
    "        self.chars = sorted(list(set(self.text)))\n",
    "        self.n_vocab = len(self.chars)\n",
    "        self.char_to_int = dict( (char, i) for i, char in enumerate(self.chars) )\n",
    "        self.int_to_char = dict( (i, char) for i, char in enumerate(self.chars) )\n",
    "        self.sequences = self.make_sequences()\n",
    "        \n",
    "    def format_text(self, text):\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Only for words\n",
    "        real_chars = ['a', 'á', 'b', 'c', 'd', 'e', 'é', 'f', 'g', 'h', 'i', 'í', 'j', 'k', 'l', 'm', 'n',\n",
    "                      'o', 'ó', 'ö', 'ő', 'p', 'q', 'r', 's', 't', 'u', 'ú', 'ü', 'ű', 'v', 'w', 'x', 'y', 'z']\n",
    "        text = list(text)\n",
    "        for i in range(len(text)):\n",
    "            if text[i] not in real_chars:\n",
    "                text[i] = ' '\n",
    "        text = ''.join(text)\n",
    "        # /Only for words\n",
    "        \n",
    "        format_items = [\n",
    "            #{'from': '\\n+', 'to': ' '},\n",
    "            #{'from': '\\r+', 'to': ' '},\n",
    "            #{'from': '\\t+', 'to': ' '},\n",
    "            {'from': ' +', 'to': ' '},\n",
    "        ]\n",
    "        for format_item in format_items:\n",
    "            text = re.sub(format_item['from'], format_item['to'], text)\n",
    "        return text\n",
    "    \n",
    "    def make_words(self):\n",
    "        words = set(self.text.split(' '))\n",
    "        correct_words = []\n",
    "        for word in words:\n",
    "            if len(word) > 0 and len(word) <= self.seq_length:\n",
    "                word += (self.seq_length - len(word)) * ' '\n",
    "                correct_words.append(word)\n",
    "        return correct_words\n",
    "\n",
    "    def make_sequences(self):\n",
    "        '''sequences = []\n",
    "        for i in range(0, len(self.text) - self.seq_length):\n",
    "            seq = self.text[i:i + self.seq_length]\n",
    "            sequences.append(seq)'''\n",
    "        \n",
    "        sequences = self.make_words()\n",
    "        sequences = [self.chars2nums(seq) for seq in sequences]\n",
    "        for i in range(len(sequences)):\n",
    "            for k in range(len(sequences[i])):\n",
    "                sequences[i][k] = make_one_hot(sequences[i][k], self.n_vocab)\n",
    "                \n",
    "        sequences = np.reshape(sequences, (len(sequences), self.seq_length, self.n_vocab))\n",
    "        return sequences\n",
    "        \n",
    "    def chars2nums(self, chars):\n",
    "        return [self.char_to_int[char] for char in chars]\n",
    "    \n",
    "    def nums2chars(self, nums):\n",
    "        return [self.int_to_char[num] for num in nums]\n",
    "    \n",
    "    def nums2str(self, nums):\n",
    "        string = ''\n",
    "        chars = self.nums2chars(nums)\n",
    "        for char in chars:\n",
    "            string += char\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = open(file).read()\n",
    "TC = TextController(text, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self, n_chars):\n",
    "        self.timesteps = seq_length\n",
    "        self.original_dim = n_chars\n",
    "        self.z_dim = z_dim\n",
    "        self.c_dim = c_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.epsilon_std = epsilon_std\n",
    "        self.build_model()\n",
    "        self.build_generator_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.x, self.z_mean, self.z_log_sigma = self.build_encoder()\n",
    "        self.z = Lambda(self.sampling, output_shape=(self.z_dim,))([self.z_mean, self.z_log_sigma])\n",
    "        self.c = Input(shape=(self.c_dim,))\n",
    "        self.z_c = concatenate([self.z, self.c])\n",
    "        self.x_gen = self.build_generator()\n",
    "        self.model = Model([self.x, self.c], self.x_gen)\n",
    "        self.model.compile(optimizer=optimizer, loss=self.vae_loss)\n",
    "        \n",
    "    def build_generator_model(self):\n",
    "        generator_input_z = Input(shape=(self.z_dim,))\n",
    "        generator_input = concatenate( [generator_input_z, self.c] )\n",
    "        h = generator_input\n",
    "        for layer in self.generator_layers:\n",
    "            h = layer(h)\n",
    "        self.generator = Model([generator_input_z, self.c], h)\n",
    "        \n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        batch_size = K.shape(z_mean)[0]\n",
    "        epsilon = K.random_normal(shape=(batch_size, self.z_dim), mean=0., stddev=self.epsilon_std)\n",
    "        return z_mean + K.exp(z_log_sigma / 2) * epsilon\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        h = x = Input(shape=(self.timesteps, self.original_dim))\n",
    "        #h = LSTM(self.intermediate_dim, activation='relu', return_sequences=True)(h)\n",
    "        h = LSTM(self.intermediate_dim, activation='relu')(h)\n",
    "        z_mean = Dense(self.z_dim)(h)\n",
    "        z_log_sigma = Dense(self.z_dim)(h)\n",
    "        return x, z_mean, z_log_sigma\n",
    "        \n",
    "    def build_generator(self):\n",
    "        self.generator_layers = [\n",
    "            RepeatVector(self.timesteps),\n",
    "            #LSTM(self.intermediate_dim, activation='relu', return_sequences=True),\n",
    "            LSTM(self.intermediate_dim, activation='relu', return_sequences=True),\n",
    "            TimeDistributed(Dense(self.original_dim, activation='sigmoid')),\n",
    "        ]\n",
    "        h = self.z_c\n",
    "        for layer in self.generator_layers:\n",
    "            h = layer(h)\n",
    "        return h\n",
    "    \n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        xent_loss = self.original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(K.sum(1 + self.z_log_sigma - K.square(self.z_mean) - K.exp(self.z_log_sigma)))\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "        #return K.mean(xent_loss)\n",
    "    \n",
    "    def train(self, x_train, c_train):\n",
    "        x_train = np.array(x_train)\n",
    "        c_train = np.array(c_train)\n",
    "        self.model.fit(x=[x_train, c_train], y=x_train, validation_split=test_split, batch_size=batch_size, epochs=epochs)\n",
    "    \n",
    "    def predict(self, x, c):\n",
    "        x = np.array([x])\n",
    "        c = np.array([c])\n",
    "        return self.model.predict([x, c])[0]\n",
    "    \n",
    "    def generate(self, z, c):\n",
    "        z = np.array([z])\n",
    "        c = np.array([c])\n",
    "        return self.generator.predict([z, c])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TG = TextGenerator(TC.n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Samples\n",
    "x_samples = TC.sequences\n",
    "c_samples = [0] * len(x_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "TG.train(x_samples, c_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_sample in x_samples[:10]:\n",
    "    predictions = TG.predict(pred_sample, 0)\n",
    "    indexes = [np.argmax(prediction) for prediction in predictions]\n",
    "    print(TC.nums2str(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    input_z = np.random.normal(loc=0., scale=1., size=(z_dim,))\n",
    "    generated = TG.generate(input_z, 0)\n",
    "    indexes = [np.argmax(gen) for gen in generated]\n",
    "    print(TC.nums2str(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
