{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_one_hot(index, count):\n",
    "    one_hot = [0] * count\n",
    "    one_hot[index] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextController:\n",
    "    def __init__(self, text, seq_length):\n",
    "        self.seq_length = seq_length\n",
    "        self.text = self.format_text(text)\n",
    "        self.chars = sorted(list(set(self.text)))\n",
    "        self.n_vocab = len(self.chars)\n",
    "        self.char_to_int = dict( (char, i) for i, char in enumerate(self.chars) )\n",
    "        self.int_to_char = dict( (i, char) for i, char in enumerate(self.chars) )\n",
    "        self.sequences = self.make_sequences()\n",
    "        \n",
    "    def format_text(self, text):\n",
    "        text = text.lower()\n",
    "        format_items = [\n",
    "            {'from': '\\n+', 'to': ' '},\n",
    "            {'from': '\\r+', 'to': ' '},\n",
    "            {'from': '\\t+', 'to': ' '},\n",
    "            {'from': ' +', 'to': ' '},\n",
    "        ]\n",
    "        for format_item in format_items:\n",
    "            text = re.sub(format_item['from'], format_item['to'], text)\n",
    "        return text\n",
    "\n",
    "    def make_sequences(self):\n",
    "        sequences = []\n",
    "        for i in range(0, len(self.text) - self.seq_length):\n",
    "            seq = self.text[i:i + self.seq_length]\n",
    "            sequences.append(seq)\n",
    "            \n",
    "        sequences = [self.chars2nums(seq) for seq in sequences]\n",
    "        for i in range(len(sequences)):\n",
    "            for k in range(len(sequences[i])):\n",
    "                sequences[i][k] = make_one_hot(sequences[i][k], self.n_vocab)\n",
    "                \n",
    "        sequences = np.reshape(sequences, (len(sequences), self.seq_length, self.n_vocab))\n",
    "        return sequences\n",
    "        \n",
    "    def chars2nums(self, chars):\n",
    "        return [self.char_to_int[char] for char in chars]\n",
    "    \n",
    "    def nums2chars(self, nums):\n",
    "        return [self.int_to_char[num] for num in nums]\n",
    "    \n",
    "    def nums2str(self, nums):\n",
    "        string = ''\n",
    "        chars = self.nums2chars(nums)\n",
    "        for char in chars:\n",
    "            string += char\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'robinson_crusoe.txt'\n",
    "seq_length = 20\n",
    "text = open(file).read()[:9999]\n",
    "TC = TextController(text, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self, n_chars, seq_length):\n",
    "        self.batch_size = 1\n",
    "        self.timesteps = seq_length\n",
    "        self.original_dim = n_chars\n",
    "        self.z_dim = 100\n",
    "        self.c_dim = 1\n",
    "        self.intermediate_dim = 1000\n",
    "        self.epsilon_std = 1\n",
    "        self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.c = Input(shape=(self.c_dim,))\n",
    "        self.x, self.z_mean, self.z_log_sigma = self.build_encoder()\n",
    "        self.z = Lambda(self.sampling, output_shape=(self.z_dim,))([self.z_mean, self.z_log_sigma])\n",
    "        self.z_c = concatenate([self.z, self.c])\n",
    "        self.x_gen = self.build_generator()\n",
    "        self.model = Model([self.x, self.c], self.x_gen)\n",
    "        self.model.compile(optimizer='rmsprop', loss=self.vae_loss)\n",
    "        \n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        batch_size = K.shape(z_mean)[0]\n",
    "        epsilon = K.random_normal(shape=(batch_size, self.z_dim), mean=0., stddev=self.epsilon_std)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        x = Input(shape=(self.timesteps, self.original_dim))\n",
    "        h = LSTM(self.intermediate_dim, activation='relu')(x)\n",
    "        z_mean = Dense(self.z_dim)(h)\n",
    "        z_log_sigma = Dense(self.z_dim)(h)\n",
    "        return x, z_mean, z_log_sigma\n",
    "        \n",
    "    def build_generator(self):\n",
    "        repeated = RepeatVector(self.timesteps)(self.z_c)\n",
    "        decoder_h = LSTM(self.intermediate_dim, activation='relu', return_sequences=True)\n",
    "        decoder_mean = TimeDistributed(Dense(self.original_dim, activation='sigmoid'))\n",
    "        h_decoded = decoder_h(repeated)\n",
    "        x_decoded_mean = decoder_mean(h_decoded)\n",
    "        return x_decoded_mean\n",
    "    \n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        xent_loss = self.original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + self.z_log_sigma - K.square(self.z_mean) - K.exp(self.z_log_sigma), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "    \n",
    "    def train(self, x_train, c_train, epochs):\n",
    "        x_train = np.array(x_train)\n",
    "        c_train = np.array(c_train)\n",
    "        self.model.fit(x=[x_train, c_train], y=x_train, batch_size=self.batch_size, epochs=epochs)\n",
    "    \n",
    "    def predict(self, x, c):\n",
    "        x = np.array([x])\n",
    "        c = np.array([c])\n",
    "        return self.model.predict([x, c])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TG = TextGenerator(TC.n_vocab, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = TC.sequences[::seq_length]\n",
    "c_train = [0] * len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TG.train(x_train, c_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = TG.predict(x_train[1], c_train[0])\n",
    "indexes = [np.argmax(prediction) for prediction in predictions]\n",
    "TC.nums2str(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
